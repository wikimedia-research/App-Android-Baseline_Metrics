---
title: "Understand Android app usage by market"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(here) # devtools::install_github("krlmlr/here")
```
```{r pkgs, include=FALSE}
library(magrittr) # install.packages(c("magrittr", "import"))
import::from(dplyr, group_by, summarize, keep_where = filter, arrange, ungroup, mutate, select, rename)
import::from(tidyr, gather, spread)
library(ggplot2)
library(ggrepel)
library(countrycode) # install.packages("countrycode")
```
```{r funcs, include=FALSE}
geo_info <- function(data) {
  # Assume country code is a ISO-2 character code and its column is named "Alpha2"
  output <- data %>%
    dplyr::mutate(
      Country = countrycode(Alpha2, "iso2c", "country.name", warn = FALSE),
      Continent = countrycode(Alpha2, "iso2c", "continent", warn = FALSE),
      Region = countrycode(Alpha2, "iso2c", "region", warn = FALSE)
    )
  message("Augmented with country, continent, and region data")
  return(output)
}
lang_info <- function(data) {
  language_codes <- ISOcodes::ISO_639_2[, c("Alpha_2", "Name")]
  language_codes %<>% keep_where(!is.na(Alpha_2)) %>% rename(Language = Name)
  language_codes$Language %<>% stringi::stri_trans_general("Latin-ASCII")
  output <- data %>%
    mutate(Alpha2 = sub("([a-z]{2,3})(_.+)?", "\\1", Alpha2)) %>%
    dplyr::left_join(language_codes, by = c("Alpha2" = "Alpha_2"))
  message("Augmented with language data")
  return(output)
}
language_aggregate <- function(data, .f, ...) {
  output <- data %>%
    dplyr::select(Date, `Package Name`, Alpha2, Language, dplyr::everything()) %>%
    gather(metric, value, -c(Date, `Package Name`, Alpha2, Language)) %>%
    dplyr::group_by(Date, `Package Name`, Alpha2, Language, metric) %>%
    dplyr::summarize(value = .f(value, ...)) %>%
    spread(metric, value)
  message("Collapsed metrics across languages")
  return(output)
}
monthly_aggregate <- function(x, .date, .f, ...) {
  y <- split(x, lubridate::floor_date(.date, unit = "month"))
  message("Collapsed metrics by month")
  return(.f(purrr::map_dbl(y, .f, ...), ...))
}
smart_formatter <- function(x, .colname, .digits = 2) {
  if (grepl("rate", .colname)) {
    return(sprintf(glue::glue("%0.{.digits}f%%"), 100 * x))
  } else {
    return(polloi::compress(x, .digits))
  }
}
summarize_metrics <- function(.grouped_data, .format = TRUE) {
  if (.format) {
    output <- .grouped_data %>%
      summarize(
        Minimum = smart_formatter(min(value, na.rm = TRUE), Metric[1], 2),
        `Daily median` = smart_formatter(mean(value, na.rm = TRUE), Metric[1], 2),
        `Monthly median` = smart_formatter(monthly_aggregate(value, Date, median, na.rm = TRUE), Metric[1], 2),
        Maximum = smart_formatter(max(value, na.rm = TRUE), Metric[1], 2),
        Latest = smart_formatter(value[which.max(Date)], Metric[1], 2)
      ) %>%
      ungroup %>%
      mutate(Latest = dplyr::if_else(Latest == "NANA", "-", Latest))
  } else {
    output <- .grouped_data %>%
      summarize(
        Minimum = min(value, na.rm = TRUE),
        `Daily median` = mean(value, na.rm = TRUE),
        `Monthly median` = monthly_aggregate(value, Date, median, na.rm = TRUE),
        Maximum = max(value, na.rm = TRUE),
        Latest = value[which.max(Date)]
      ) %>%
      ungroup
  }
  return(output)
}
percentile <- function(x) {
  output <- vapply(x, function(y) {
    return(sum(x <= y))
  }, 0L) / length(x)
  return(output)
}
```

This report for Phabricator ticket [T184089](https://phabricator.wikimedia.org/T184089) was last generated on `r format(lubridate::today(), "%B %d, %Y")`.

```{r data, cache=TRUE}
# installs_country <- here("T184089/data/concatenated/installs-country.csv") %>%
#   readr::read_csv() %>% rename(Alpha2 = Country) %>% select(-dplyr::contains("events")) %>% geo_info
# installs_language <- here("T184089/data/concatenated/installs-language.csv") %>%
#   readr::read_csv(col_types = "Dcciiiiiiiiiiii") %>%
#   select(-dplyr::contains("events")) %>% rename(Alpha2 = Language) %>%
#   lang_info %>% language_aggregate(sum, na.rm = TRUE) %>%
#   keep_where(!is.na(Language))
# installs_overview <- here("T184089/data/concatenated/installs-overview.csv") %>%
#   readr::read_csv() %>% select(-dplyr::contains("events"))
retained_country <- here("T184089/data/concatenated/retained_installers-country.csv") %>%
  readr::read_csv() %>% rename(Alpha2 = Country) %>%
  geo_info
retained_play_country <- here("T184089/data/concatenated/retained_installers-play_country.csv") %>%
  readr::read_csv() %>% rename(Alpha2 = `Country  Play Store`) %>%
  geo_info
retained_channel <- here("T184089/data/concatenated/retained_installers-channel.csv") %>%
  readr::read_csv()
ratings_country <- here("T184089/data/concatenated/ratings-country.csv") %>%
  readr::read_csv() %>% rename(Alpha2 = Country) %>%
  geo_info
ratings_language <- here("T184089/data/concatenated/ratings-language.csv") %>%
  readr::read_csv() %>% rename(Alpha2 = Language) %>%
  lang_info %>% language_aggregate(mean, na.rm = TRUE) %>%
  keep_where(!is.na(Language))
ratings_overview <- here("T184089/data/concatenated/ratings-overview.csv") %>%
  readr::read_csv()
overall_au <- here("T184089/data/active_users/overall_active_users.csv") %>%
  readr::read_csv() %>%
  mutate(stickiness = dau / mau)
mau_country <- here("T184089/data/active_users/mau_country.csv") %>%
  readr::read_csv() %>%
  rename(mau = unique_count, Alpha2 = country_code) %>%
  geo_info
dau_country <- here("T184089/data/active_users/dau_country.csv") %>%
  readr::read_csv() %>%
  rename(dau = unique_count) %>%
  select(-country_code) %>%
  dplyr::left_join(mau_country, by = c("year", "month", "country", "platform")) %>%
  mutate(
    date = as.Date(paste(year, month, day, sep = "-")),
    stickiness = dau / mau
  )
```
```{r installs_summary, eval=FALSE}
installs_overview %>%
  gather(metric, value, -c(Date, `Package Name`)) %>%
  mutate(metric = dplyr::if_else(grepl("^Current", metric), paste(metric, "(Deprecated)"), metric)) %>%
  group_by(Metric = metric) %>%
  summarize_metrics %>%
  select(-Minimum) %>%
  knitr::kable(format = "markdown", align = c("l", "r", "r", "r", "r"))
```

## Retained Installs

**Acquisition channels** in [acquisition reports](https://play.google.com/apps/publish/?account=6169333749249604352#AcquisitionPerformancePlace:p=org.wikipedia&apr=RETAINED_INSTALLERS) include Play Store (users find the app by browsing or searching on the Play Store app), Google Search, third-party referrers (users find the app via an untagged deep link to the Play Store), and AdWords (Google's advertising service).

```{r retained_channels, fig.width=12, fig.height=9}
retained_summary <- retained_channel %>%
  keep_where(Date >= "2017-12-01") %>%
  gather(metric, value, -c(Date, `Package Name`, `Acquisition Channel`)) %>%
  dplyr::group_by(`Acquisition Channel`, Metric = metric) %>%
  summarize_metrics(.format = FALSE) %>%
  select(-Latest) %>%
  keep_where(!grepl("(UTM)", `Acquisition Channel`, fixed = TRUE))
benchmarks <- dplyr::data_frame(
  Metric = c(
    "Visitor to Installer conversion rate",
    "Installer to 1 day retention rate",
    "Installer to 7 days retention rate",
    "Installer to 15 days retention rate",
    "Installer to 30 days retention rate"
  ),
  Benchmark = c(
    33.6,
    75.1,
    61.2,
    53.9,
    46.3
  )
); benchmarks$Benchmark <- benchmarks$Benchmark / 100
retained_summary %<>% keep_where(!Metric %in% c("Median Visitor to Installer conversion rate benchmark"))
retained_summary$Metric %<>% factor(levels = c(
  "Installers retained for 1 day", "Installers retained for 7 days",
  "Installers retained for 15 days", "Installers retained for 30 days",
  "Installer to 1 day retention rate", "Installer to 7 days retention rate",
  "Installer to 15 days retention rate", "Installer to 30 days retention rate",
  "Store Listing Visitors", "Installers", "Visitor to Installer conversion rate"
))
benchmarks$Metric %<>% factor(levels = levels(retained_summary$Metric))
retained_summary %<>% arrange(Metric, `Acquisition Channel`)
# log10p1 <- function(x) log10(x + 1)
# retained_summary$Minimum[!grepl("rate", retained_summary$Metric)] %<>% log10p1
# retained_summary$`Monthly median`[!grepl("rate", retained_summary$Metric)] %<>% log10p1
# retained_summary$Maximum[!grepl("rate", retained_summary$Metric)] %<>% log10p1
smart_labeller <- function(x, m, log_transformed = FALSE) {
  percentage <- sprintf("%0.1f%%", 100 * x)
  if (log_transformed) {
    compressed <- polloi::compress(ceiling(10 ^ x), 1)
  } else {
    compressed <- polloi::compress(ceiling(x), 1)
  }
  compressed[grepl("rate", m)] <- percentage[grepl("rate", m)]
  return(compressed)
}
ggplot(retained_summary, aes(x = `Acquisition Channel`)) +
  geom_hline(aes(yintercept = Benchmark), data = benchmarks, linetype = "dashed") +
  geom_pointrange(aes(ymin = Minimum, ymax = Maximum, y = `Daily median`)) +
  geom_text(aes(y = `Daily median`, label = smart_labeller(`Daily median`, Metric)), vjust = "bottom", hjust = "left", nudge_x = 0.2) +
  scale_y_continuous("Median across December 2017 and Janurary 2018", labels = function(x) {
    if (all(x <= 1.0, na.rm = TRUE)) {
      return(sprintf("%0.0f%%", 100 * x))
    } else {
      return(polloi::compress(x, 0))
    }
  }) +
  coord_flip() +
  facet_wrap(~ Metric, scales = "free_x", ncol = 4) +
  labs(
    title = "Wikipedia Android app retention metrics by acquisition channel",
    subtitle = "Bars indicate minimum and maximum observed during the last 2 months",
    caption = "Google calculated median rates on Play Store from December 2017, which are represented by the dashed lines. Those benchmarks are based on the performance of popular free apps in the Books & Reference category."
  ) +
  wmf::theme_facet()
```

* Very few people find the app via AdWords and fewer still actually install it and fewer still keep it installed for more than a day.
* Users tend to find the app organically through the Play Store (and that's _basically_ it).
* A little over a third of users who found the app via Google Search end up installing it.
* Users who found the app via Play Store and AdWords campaigns and then installed it were more likely to keep the app installed for 30 days than users who found it via Google search and other third-party referrers.
* Compared to the median conversion and retention rates, the Wikipedia app is way better at 1/7/15/30-day install retention than other popular free apps in the *Books & Reference* category.

```{r retained_region, fig.width=12, fig.height=8}
retained_region <- retained_country %>%
  keep_where(!is.na(Region), Date >= "2017-12-01") %>%
  select(c(
    Date, Country, Continent, Region,
    `Store Listing Visitors`, Installers,
    `Installers retained for 1 day`,
    `Installers retained for 7 days`,
    `Installers retained for 30 days`
  )) %>%
  gather(metric, value, -c(Date, Country, Continent, Region)) %>%
  group_by(Date, Region, Continent, metric) %>%
  summarize(value = sum(value, na.rm = TRUE)) %>%
  ungroup %>%
  spread(metric, value, fill = 0) %>%
  mutate(
    `Visitor to Installer conversion rate` = Installers / `Store Listing Visitors`,
    `Installer to 1 day retention rate` = `Installers retained for 1 day` / Installers,
    `Installer to 7 days retention rate` = `Installers retained for 7 days` / Installers,
    `Installer to 30 days retention rate` = `Installers retained for 30 days` / Installers
  ) %>%
  select(-dplyr::contains("retained")) %>%
  gather(Metric, Value, -c(Date, Region, Continent)) %>%
  group_by(Region, Continent, Metric) %>%
  summarize(Value = median(Value, na.rm = TRUE)) %>%
  ungroup %>%
  mutate(Metric = factor(Metric, levels = c("Store Listing Visitors", "Installers", "Visitor to Installer conversion rate", "Installer to 1 day retention rate", "Installer to 7 days retention rate", "Installer to 30 days retention rate")))
retained_region$Region %<>% factor(levels = unique(retained_region$Region[order(retained_region$Continent, retained_region$Region, decreasing = TRUE)]))
ggplot(retained_region, aes(x = Region, y = Value, color = Continent)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_pointrange(aes(ymin = 0, ymax = Value)) +
  scale_y_continuous("Median across December 2017 and Janurary 2018", labels = function(x) {
    if (all(x <= 1.0)) {
      return(sprintf("%0.0f%%", 100 * x))
    } else {
      return(polloi::compress(x, 0))
    }
  }) +
  facet_wrap(~ Metric, scales = "free_x", ncol = 3) +
  coord_flip() +
  ggtitle("Wikipedia Android app conversion and retention statistics by region") +
  wmf::theme_facet()
```

* The app's Play Store page is not seen by many users in Africa, but the conversion rates for those regions are some of the highest rates compared to regions in other continents.
* Way more people look at the app in the Play Store in Southern Asia than in any other region, but the conversion rate is close to the Play Store median.
* Some of our lowest conversion rates are in Central America, South America, South-Eastern Asia, Western Asia, Southern Europe, and especially oceanic regions like Polynesia.
* Even when users in those low-conversion regions do install the app, less than 30% of them keep the app installed more than 30 days.
* 30-day retention rates are highest in North America, Europe in general, and Australia & New Zealand.

## Ratings

[App ratings over time](https://play.google.com/apps/publish/?account=6169333749249604352#RatingsPlace:p=org.wikipedia) are calculated from users' 1-5 star ratings.

```{r ratings_summary, fig.width=9, fig.height=4.5}
ratings_summary <- ratings_overview %>%
  gather(`Type of rating`, Rating, -c(Date, `Package Name`)) %>%
  mutate(`Type of rating` = sub(" Rating", "", `Type of rating`, fixed = TRUE))
ggplot(ratings_summary, aes(x = Date, y = Rating, color = `Type of rating`)) +
  geom_line(alpha = 0.75) +
  scale_color_brewer(palette = "Set1") +
  geom_smooth(
    method = "gam", formula = y ~ s(x, k = 21), se = FALSE,
    data = keep_where(ratings_summary, `Type of rating` == "Daily Average")
  ) +
  scale_x_date(date_breaks = "2 months", date_labels = "%b\n%Y") +
  scale_y_continuous(limits = c(4.25, 5.0)) +
  ggtitle("Wikipedia Android app ratings over time") +
  wmf::theme_min()
```

```{r ratings_languages, fig.width=9, fig.height=4.5}
ratings_languages <- ratings_language %>%
  keep_where(!is.na(Language), Date > "2017-12-01") %>%
  group_by(Language) %>%
  summarize(`Total Average Rating` = median(`Total Average Rating`, na.rm = TRUE)) %>%
  arrange(desc(`Total Average Rating`)) %>%
  mutate(Percentile = percentile(`Total Average Rating`)) %>%
  keep_where(Percentile <= 0.1 | (Percentile > 0.45 & Percentile <= 0.55) | Percentile >= 0.9) %>%
  mutate(
    Group = factor(dplyr::case_when(
      Percentile <= 0.1 ~ "Bottom 10%",
      Percentile >= 0.9 ~ "Top 10%",
      TRUE ~ "Middle 10%"
    ), levels = rev(c("Bottom 10%", "Middle 10%", "Top 10%")))
  )
ratings_languages$Language %<>% factor(levels = unique(ratings_languages$Language[order(ratings_languages$Group, ratings_languages$Language, decreasing = TRUE)]))
ggplot(ratings_languages, aes(y = `Total Average Rating`, x = Language, color = Group)) +
  geom_pointrange(aes(ymin = 0, ymax = `Total Average Rating`)) +
  coord_flip() +
  labs(
    color = "Percentile", y = "Average rating on Play Store across December 2017 and Janurary 2018",
    title = "Average rating of Wikipedia Android app on Play Store by language"
  ) +
  wmf::theme_min()
```

* The languages whose users rated the app the lowest (e.g. Norwegian and Japanese) are still close to 4 stars on average.

**Note to self**: would be useful at some point to also compare by families of languages, to see if we're doing well/poorly in specific families (e.g. Caucasian vs Asian vs Indo-European).

```{r ratings_region, fig.width=9, fig.height=4.5}
ratings_region <- ratings_country %>%
  keep_where(!is.na(Region), !is.na(Continent), Date > "2017-12-01") %>%
  group_by(Continent, Region) %>%
  summarize(`Total Average Rating` = median(`Total Average Rating`, na.rm = TRUE)) %>%
  arrange(desc(`Total Average Rating`))
ratings_continent <- ratings_country %>%
  keep_where(!is.na(Region), !is.na(Continent), Date > "2017-12-01") %>%
  group_by(Continent) %>%
  summarize(`Total Average Rating` = median(`Total Average Rating`, na.rm = TRUE)) %>%
  arrange(`Total Average Rating`) %>%
  mutate(Order = 1:n()) %>%
  select(-`Total Average Rating`)
ratings_region %<>% dplyr::left_join(ratings_continent, by = "Continent")
ratings_region$Region %<>% factor(levels = unique(ratings_region$Region[order(ratings_region$Order, ratings_region$`Total Average Rating`, decreasing = TRUE)]))
ratings_region$Continent %<>% factor(levels = ratings_continent$Continent)
ggplot(ratings_region, aes(x = Region, color = Continent, y = `Total Average Rating`)) +
  geom_pointrange(aes(ymin = 0, ymax = `Total Average Rating`)) +
  coord_flip() +
  labs(
    color = "Continent, arranged by average across regions",
    y = "Average rating on Play Store across December 2017 and Janurary 2018",
    title = "Average rating of Wikipedia Android app on Play Store by region & continent"
  ) +
  wmf::theme_min()
```

* The average rating is lowest in Africa across all regions.
* Regions where the app is rated the lowest include:
    * Micronesia (e.g. Palau, Northern Mariana Islands, Federated States of Micronesia)
    * Western Europe (e.g. Belgium, France, Germany)
    * Eastern Asia (e.g. Japan, South Korea)
* Regions where the app is rated the highest include:
    * Polynesia (Samoa, American Samoa, French Polynesia)
    * Eastern Europe (e.g. Belarus, Poland, Russia)
    * Central Asia (e.g. Kazakhstan, Tajikistan, Uzbekistan)
    * Southern Asia (e.g. India, Afghanistan, Pakistan)

## App Stickiness

```{r stickiness_overall, eval=FALSE}
ggplot(overall_au, aes(x = date, y = stickiness, color = platform)) +
  geom_line() +
  scale_x_date(date_labels = "%b\n%Y", date_breaks = "1 month", date_minor_breaks = "1 month") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    x = "Date", y = "Stickiness (DAU/MAU)", color = "Platform",
    title = "Wikipedia app \"stickiness %\" over time",
    subtitle = "DAU = daily active users, MAU = monthly active users",
    caption = "App stickiness of 25% means that day represents 1/4 of users that month.\nNote on iOS October jump: Apple named the app an Editor's Choice on Oct 27, 2017."
  ) +
  wmf::theme_min()
```
```{r stickiness_region, fig.width=16, fig.height=8}
stickiness_region <- dau_country %>%
  keep_where(!is.na(Region), date < "2018-02-01", platform == "Android") %>%
  group_by(Date = date, Continent, Region) %>%
  summarize(dau = sum(dau), mau = sum(mau)) %>%
  mutate(stickiness = dau / mau) %>%
  ungroup
region_labels <- stickiness_region %>%
  group_by(Continent, Region) %>%
  dplyr::top_n(1, -stickiness) %>%
  ungroup %>%
  arrange(Continent, desc(stickiness)) %>%
  group_by(Continent) %>%
  mutate(RegionN = as.character(as.numeric(factor(Region, levels = Region)))) %>%
  ungroup
stickiness_region <- region_labels %>%
  select(Region, RegionN) %>%
  dplyr::left_join(stickiness_region, ., by = "Region")
stickiness_continent <- dau_country %>%
  keep_where(!is.na(Region), date < "2018-02-01", platform == "Android") %>%
  mutate(Region = Continent, Continent = "Overall") %>%
  group_by(Date = date, Continent, Region) %>%
  summarize(dau = sum(dau), mau = sum(mau)) %>%
  mutate(stickiness = dau / mau) %>%
  ungroup
continent_labels <- stickiness_continent %>%
  group_by(Continent, Region) %>%
  dplyr::top_n(1, -stickiness) %>%
  ungroup %>%
  arrange(Continent, desc(stickiness)) %>%
  mutate(RegionN = as.character(as.numeric(factor(Region, levels = Region))))
stickiness_continent <- continent_labels %>%
  select(Region, RegionN) %>%
  dplyr::left_join(stickiness_continent, ., by = "Region")
ggplot() +
  # Background showing all regions:
  geom_line(
    data = select(stickiness_region, -Continent),
    aes(x = Date, y = stickiness, group = Region),
    alpha = 0.2, size = 0.4
  ) +
  # Overall stickiness for comparison:
  geom_line(
    data = keep_where(overall_au, platform == "Android", date >= "2017-12-01"),
    aes(x = date, y = stickiness),
    linetype = "dashed"
  ) +
  # Per-region, per-continent stickiness:
  geom_line(
    data = rbind(stickiness_region, stickiness_continent[, names(stickiness_region)]),
    aes(x = Date, y = stickiness, group = Region, color = RegionN),
    size = 0.6
  ) +
  # Label the regions:
  geom_point(
    data = rbind(region_labels, continent_labels[, names(region_labels)]),
    aes(x = Date, y = stickiness, color = RegionN),
    size = 3
  ) +
  geom_label_repel(
    data = rbind(region_labels, continent_labels[, names(region_labels)]),
    aes(x = Date, y = stickiness, label = Region, fill = RegionN),
    fontface = "bold", color = "white", segment.color = "black", seed = 0
  ) +
  # Extra stuff that makes the whole thing prettier:
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  guides(color = FALSE, fill = FALSE) +
  scale_y_continuous("Stickiness (DAU/MAU)", labels = scales::percent_format()) +
  scale_x_date(
    date_breaks = "14 days", date_minor_breaks = "7 days",
    date_labels = "%d %b\n%Y"
  ) +
  facet_wrap(~ Continent) +
  wmf::theme_facet(14) +
  labs(
    title = "Wikipedia Android app \"stickiness %\" by region & continent",
    subtitle = "DAU = daily active users, MAU = monthly active users, dashed line represents overall stickiness for comparison",
    caption = "App stickiness of 25% means that day represents 1/4 of users that month. Countries are grouped into regions as defined by World Bank Development Indicators."
  )
```

- **Note**: refer to tables below for % of active users each continent and region was responsible for in January 2018
- Overall stickiness is driven almost entirely by the app's stickiness in Europe (which was responsible for nearly half of all active users)
- Highest stickiness is in Northern America and Europe in general
- Lowest stickiness is in Africa (Western Africa countries specifically) and Southern/South-Eastern Asia
- Other than Australia & New Zealand (where the app has high stickiness relative to other regions), the app is doing poorly in Oceanic regions (which had less than 1.5K users each)

```{r continental_shares}
avg_continental <- dau_country %>%
  keep_where(!is.na(Continent), year == 2018, month == 1) %>%
  group_by(Continent, date) %>%
  summarize(dau = sum(dau), mau = sum(mau)) %>%
  mutate(stickiness = dau / mau) %>%
  summarize(`Avg daily stickiness` = sprintf("%.1f%%", 100 * mean(stickiness)))
mau_country %>%
  keep_where(!is.na(Continent), year == 2018, month == 1) %>%
  group_by(Continent) %>%
  summarize(mau = sum(mau)) %>%
  mutate(
    `Users in Jan '18` = polloi::compress(mau, 2),
    Share = sprintf("%.1f%%", 100 * mau / sum(mau))
  ) %>%
  arrange(Continent) %>%
  select(-mau) %>%
  dplyr::left_join(avg_continental, by = "Continent") %>%
  knitr::kable(format = "markdown", align = c("l", "r", "r", "r"))
```
```{r regional_shares}
avg_regional <- dau_country %>%
  keep_where(!is.na(Region), year == 2018, month == 1) %>%
  group_by(Continent, Region, date) %>%
  summarize(dau = sum(dau), mau = sum(mau)) %>%
  mutate(stickiness = dau / mau) %>%
  summarize(`Avg daily stickiness` = sprintf("%.1f%%", 100 * mean(stickiness)))
mau_country %>%
  keep_where(!is.na(Region), year == 2018, month == 1) %>%
  group_by(Continent, Region) %>%
  summarize(mau = sum(mau)) %>%
  mutate(
    `Users in Jan '18` = polloi::compress(mau, 2),
    `Share within continent` = sprintf("%.1f%%", 100 * mau / sum(mau))
  ) %>%
  arrange(Continent, Region) %>%
  select(-mau) %>%
  dplyr::left_join(avg_regional, by = c("Continent", "Region")) %>%
  knitr::kable(format = "markdown", align = c("l", "l", "r", "r", "r"))
```

## Sessions

Blockers:

- [ ] resolve sampling bug ([T186682](https://phabricator.wikimedia.org/T186682))
- [ ] resolve timestamp bug ([T186768](https://phabricator.wikimedia.org/T186768))

TODO:

- [ ] load [MobileWikiAppSessions](https://meta.wikimedia.org/wiki/Schema:MobileWikiAppSessions) events into Hadoop/Hive
- [ ] join with `wmf.webrequest` on `appInstallId` (found under the `wmfuuid` key in [X-Analytics](https://wikitech.wikimedia.org/wiki/X-Analytics))
- [ ] calculate summary metrics of session lengths by country
